{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f71eb20-0cb2-4e2c-9c39-506ac02ab037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from init import *\n",
    "from src import config\n",
    "from src.utils import log_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "import mlflow.catboost\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "optuna.logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf45189-8613-425e-b93c-2f0126e52d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_pickle(config.DATA_PATH + \"processed/X_train_fe.pkl\")\n",
    "test = pd.read_pickle(config.DATA_PATH + \"processed/X_test_fe.pkl\")\n",
    "sample = pd.read_csv(config.DATA_PATH + 'raw/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b798122-2e35-4a42-8b18-4cbb86f88e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "selected_features = [\n",
    "    'Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate',\n",
    "    'HR_per_min', 'Age_Group_Adult', 'Age_Group_Senior'\n",
    "]\n",
    "X = train[selected_features].copy()\n",
    "y = train[\"Calories\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488769be-3012-4c77-8aeb-272c8345353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configurations\n",
    "model_configs = {\n",
    "    \"rf\": {\n",
    "        \"class\": RandomForestRegressor,\n",
    "        \"params\": lambda t: {\n",
    "            \"n_estimators\": t.suggest_int('n_estimators', 50, 300),\n",
    "            \"max_depth\": t.suggest_int('max_depth', 3, 15),\n",
    "            \"max_features\": t.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1\n",
    "        }\n",
    "    },\n",
    "    \"hgb\": {\n",
    "        \"class\": HistGradientBoostingRegressor,\n",
    "        \"params\": lambda t: {\n",
    "            \"learning_rate\": t.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            \"max_depth\": t.suggest_int('max_depth', 3, 10),\n",
    "            \"max_iter\": t.suggest_int('max_iter', 50, 200),\n",
    "            \"l2_regularization\": t.suggest_float('l2_regularization', 0.0, 1.0),\n",
    "            \"random_state\": 42\n",
    "        }\n",
    "    },\n",
    "    \"xgb\": {\n",
    "        \"class\": XGBRegressor,\n",
    "        \"params\": lambda t: {\n",
    "            \"n_estimators\": t.suggest_int('n_estimators', 50, 200),\n",
    "            \"max_depth\": t.suggest_int('max_depth', 3, 10),\n",
    "            \"learning_rate\": t.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            \"subsample\": t.suggest_float('subsample', 0.6, 1.0),\n",
    "            \"colsample_bytree\": t.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            \"gamma\": t.suggest_float('gamma', 0, 5),\n",
    "            \"reg_alpha\": t.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "            \"reg_lambda\": t.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1\n",
    "        }\n",
    "    },\n",
    "    \"lgbm\": {\n",
    "        \"class\": LGBMRegressor,\n",
    "        \"params\": lambda t: {\n",
    "            \"n_estimators\": t.suggest_int('n_estimators', 50, 300),\n",
    "            \"max_depth\": t.suggest_int('max_depth', 3, 15),\n",
    "            \"learning_rate\": t.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            \"num_leaves\": t.suggest_int('num_leaves', 20, 100),\n",
    "            \"subsample\": t.suggest_float('subsample', 0.6, 1.0),\n",
    "            \"colsample_bytree\": t.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            \"reg_alpha\": t.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "            \"reg_lambda\": t.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "            \"random_state\": 42,\n",
    "            \"verbosity\": -1,\n",
    "            \"n_jobs\": -1\n",
    "        }\n",
    "    },\n",
    "    \"cat\": {\n",
    "        \"class\": CatBoostRegressor,\n",
    "        \"params\": lambda t: {\n",
    "            \"iterations\": t.suggest_int(\"iterations\", 100, 500),\n",
    "            \"depth\": t.suggest_int(\"depth\", 4, 10),\n",
    "            \"learning_rate\": t.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"l2_leaf_reg\": t.suggest_float(\"l2_leaf_reg\", 1.0, 10.0),\n",
    "            \"random_seed\": 42,\n",
    "            \"verbose\": 0\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c98c04d-3d4c-42c2-b8ae-be4193243a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning function\n",
    "def run_optuna_tuning(models_to_run=None, n_trials=100, X=None, y=None, save_dir=\"../logs/best_params\", experiment_name=\"Calories - Optuna Tuning\"):\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    mlflow.set_tracking_uri(\"file:../logs/mlruns\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    def make_objective(model_class, param_func):\n",
    "        def objective(trial):\n",
    "            model = model_class(**param_func(trial))\n",
    "            score = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=3).mean()\n",
    "            return -score\n",
    "        return objective\n",
    "\n",
    "    selected = {k: v for k, v in model_configs.items() if models_to_run is None or k in models_to_run}\n",
    "    studies = {}\n",
    "    for name, config in selected.items():\n",
    "        print(f\"✅ Running Optuna for {name.upper()}...\")\n",
    "        with mlflow.start_run(run_name=f\"Tuning_{name.upper()}\"):\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            study.optimize(make_objective(config[\"class\"], config[\"params\"]), n_trials=n_trials)\n",
    "\n",
    "            best_params = study.best_params\n",
    "            best_score = study.best_value\n",
    "            mlflow.log_params({f\"{name}__{k}\": v for k, v in best_params.items()})\n",
    "            mlflow.log_metric(f\"{name.upper()}_best_score\", best_score)\n",
    "\n",
    "            with open(f\"{save_dir}/{name}.json\", \"w\") as f:\n",
    "                json.dump(best_params, f, indent=2)\n",
    "            print(f\"✅ {name.upper()} best params saved and logged.\")\n",
    "            studies[name] = study\n",
    "    return studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abf211cb-7856-4c82-a08f-c7c4a7616d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to log model after training\n",
    "def save_params_to_json(name, params):\n",
    "    with open(f\"../logs/best_params/{name}.json\", \"w\") as f:\n",
    "        json.dump(params, f, indent=2)\n",
    "\n",
    "def train_log_model(name, model, params, pred_val, score, mlflow_module):\n",
    "    mlflow.log_params({f\"{name}__{k}\": v for k, v in params.items()})\n",
    "    mlflow.log_metric(f\"RMSLE_{name.upper()}\", score)\n",
    "    signature = infer_signature(X_val, pred_val)\n",
    "    mlflow_module.log_model(model, artifact_path=f\"{name}_model\", signature=signature, input_example=X_val.iloc[:1])\n",
    "    save_params_to_json(name, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d57db-faba-49fe-b74c-69eb3c2f2aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Running Optuna for RF...\n"
     ]
    }
   ],
   "source": [
    "# Run tuning\n",
    "run_optuna_tuning(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a0396-8788-45b0-af20-7e256847f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train + log models\n",
    "model_classes = {\n",
    "    \"rf\": (RandomForestRegressor, mlflow.sklearn),\n",
    "    \"hgb\": (HistGradientBoostingRegressor, mlflow.sklearn),\n",
    "    \"xgb\": (XGBRegressor, mlflow.xgboost),\n",
    "    \"lgbm\": (LGBMRegressor, mlflow.lightgbm),\n",
    "    \"cat\": (CatBoostRegressor, mlflow.catboost)\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=\"tuned_models_all_5\"):\n",
    "    scores = {}\n",
    "    for name, (model_cls, mlflow_module) in model_classes.items():\n",
    "        with open(f\"../logs/best_params/{name}.json\", \"r\") as f:\n",
    "            params = json.load(f)\n",
    "\n",
    "        # Adjust params\n",
    "        const = dict(random_state=42) if name != \"cat\" else dict(random_seed=42, verbose=0, train_dir=\"../logs/catboost_logs\")\n",
    "        const.update(params)\n",
    "\n",
    "        model = model_cls(**const)\n",
    "        model.fit(X_train, y_train)\n",
    "        val_pred = model.predict(X_val)\n",
    "        score = np.sqrt(mean_squared_log_error(y_val, np.clip(val_pred, 0, None)))\n",
    "        scores[name.upper()] = score\n",
    "        log_score(\n",
    "            name.upper() + \" Tuned\",\n",
    "            score,\n",
    "            f\"Optuna-tuned {name.upper()}, best features, 100 trials\"\n",
    "        )\n",
    "\n",
    "\n",
    "        train_log_model(name, model, params, val_pred, score, mlflow_module)\n",
    "\n",
    "    print(\"\\n✅ RMSLE Scores:\")\n",
    "    for model, score in scores.items():\n",
    "        print(f\"RMSLE {model:5s}: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6d1b0-f73d-477e-80c2-6179536e83ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "def send_sms(phone_email, subject, body):\n",
    "    msg = MIMEText(body)\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = \"your_email@gmail.com\"\n",
    "    msg['To'] = phone_email\n",
    "\n",
    "    with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n",
    "        server.login(\"saayedalam@gmail.com\", \"tbac orha quvt mzgs\")  # ← Paste app password here\n",
    "        server.send_message(msg)\n",
    "\n",
    "# Send to Fido via email-to-SMS\n",
    "send_sms(\"saayedalam@gmail.com\", \"ML Job\", \"✅ Model tuning is complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e6603a-d3a3-4bb3-9ede-537e7e10be49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaff7b3-292a-41a7-ad52-e163cb8aac29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data-lab)",
   "language": "python",
   "name": "data-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
