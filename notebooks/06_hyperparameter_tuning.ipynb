{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b628931f-3492-4538-9d59-1d2fda87bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from init import *  # Adds project root to sys.path\n",
    "from src import config\n",
    "from src.utils import log_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import optuna\n",
    "import logging\n",
    "\n",
    "optuna.logging.set_verbosity(logging.WARNING)\n",
    "optuna.logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "420a0224-3c13-4f8e-941e-de99b5f563f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_pickle(config.DATA_PATH + \"processed/X_train_fe.pkl\")\n",
    "test = pd.read_pickle(config.DATA_PATH + \"processed/X_test_fe.pkl\")\n",
    "sample = pd.read_csv(config.DATA_PATH + 'raw/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d0dd1a9-57ea-4ece-83fa-2888248b9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preaparting only with Best Features from previous notebook\n",
    "# 1. Define the exact features you want\n",
    "selected_features = [\n",
    "    'Sex',\n",
    "    'Age',\n",
    "    'Height',\n",
    "    'Weight',\n",
    "    'Duration',\n",
    "    'Heart_Rate',\n",
    "    'HR_per_min',\n",
    "    'Age_Group_Adult',\n",
    "    'Age_Group_Senior'\n",
    "]\n",
    "\n",
    "# 2. Extract X and y\n",
    "X = train[selected_features].copy()\n",
    "y = train[\"Calories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c573bfc3-4079-4bd2-8ea4-4acac2cb4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cac220ea-7c2c-4d86-b48f-42ee7207e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning - Optuna\n",
    "\n",
    "# Random Forest\n",
    "def rf_objective(trial):\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 300),\n",
    "        max_depth=trial.suggest_int('max_depth', 3, 15),\n",
    "        max_features=trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    score = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=3).mean()\n",
    "    return -score\n",
    "\n",
    "# HistGradientBoosting\n",
    "def hgb_objective(trial):\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        max_depth=trial.suggest_int('max_depth', 3, 10),\n",
    "        max_iter=trial.suggest_int('max_iter', 50, 200),\n",
    "        l2_regularization=trial.suggest_float('l2_regularization', 0.0, 1.0),\n",
    "        random_state=42\n",
    "    )\n",
    "    score = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=3).mean()\n",
    "    return -score\n",
    "\n",
    "# XGBoost\n",
    "def xgb_objective(trial):\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "        max_depth=trial.suggest_int('max_depth', 3, 10),\n",
    "        learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        subsample=trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        colsample_bytree=trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        gamma=trial.suggest_float('gamma', 0, 5),\n",
    "        reg_alpha=trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        reg_lambda=trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    score = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=3).mean()\n",
    "    return -score\n",
    "\n",
    "# LightGBM\n",
    "def lgbm_objective(trial):\n",
    "    model = LGBMRegressor(\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 300),\n",
    "        max_depth=trial.suggest_int('max_depth', 3, 15),\n",
    "        learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        num_leaves=trial.suggest_int('num_leaves', 20, 100),\n",
    "        subsample=trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        colsample_bytree=trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        reg_alpha=trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        reg_lambda=trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    score = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=3).mean()\n",
    "    return -score\n",
    "\n",
    "# CatBoost\n",
    "def catboost_objective(trial):\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=trial.suggest_int(\"iterations\", 100, 500),\n",
    "        depth=trial.suggest_int(\"depth\", 4, 10),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        l2_leaf_reg=trial.suggest_float(\"l2_leaf_reg\", 1.0, 10.0),\n",
    "        random_seed=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    score = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=3).mean()\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90723d-5fad-4363-8b31-d8fb09babffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Running Optuna for RandomForest...\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna on All Models\n",
    "\n",
    "print(\"✅ Running Optuna for RandomForest...\")\n",
    "rf_study = optuna.create_study(direction='minimize')\n",
    "rf_study.optimize(rf_objective, n_trials=20)\n",
    "print(\"Best RF Params:\", rf_study.best_params)\n",
    "\n",
    "print(\"✅ Running Optuna for HGB...\")\n",
    "hgb_study = optuna.create_study(direction='minimize')\n",
    "hgb_study.optimize(hgb_objective, n_trials=20)\n",
    "print(\"Best HGB Params:\", hgb_study.best_params)\n",
    "\n",
    "print(\"✅ Running Optuna for XGB...\")\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "xgb_study.optimize(xgb_objective, n_trials=20)\n",
    "print(\"Best XGB Params:\", xgb_study.best_params)\n",
    "\n",
    "print(\"✅ Running Optuna for LGBM...\")\n",
    "lgbm_study = optuna.create_study(direction='minimize')\n",
    "lgbm_study.optimize(lgbm_objective, n_trials=20)\n",
    "print(\"Best LGBM Params:\", lgbm_study.best_params)\n",
    "\n",
    "print(\"✅ Running Optuna for CatBoost...\")\n",
    "cat_study = optuna.create_study(direction='minimize')\n",
    "cat_study.optimize(catboost_objective, n_trials=100)\n",
    "print(\"Best CatBoost Params:\", cat_study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d36bfae-5866-407c-b382-d967294d0520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data-lab)",
   "language": "python",
   "name": "data-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
