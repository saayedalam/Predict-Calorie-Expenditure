{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b628931f-3492-4538-9d59-1d2fda87bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from init import *  # Adds project root to sys.path\n",
    "from src import config\n",
    "from src.utils import log_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.base import clone\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import optuna\n",
    "import logging\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.catboost\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "optuna.logging.set_verbosity(logging.WARNING)\n",
    "optuna.logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420a0224-3c13-4f8e-941e-de99b5f563f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Load data\n",
    "train = pd.read_pickle(config.DATA_PATH + \"processed/X_train_fe.pkl\")\n",
    "test = pd.read_pickle(config.DATA_PATH + \"processed/X_test_fe.pkl\")\n",
    "sample = pd.read_csv(config.DATA_PATH + 'raw/sample_submission.csv')\n",
    "\"\"\"\n",
    "# Load data\n",
    "train = pd.read_csv(config.DATA_PATH + 'raw/train.csv')\n",
    "test = pd.read_csv(config.DATA_PATH + 'raw/test.csv')\n",
    "sample = pd.read_csv(config.DATA_PATH + 'raw/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0dd1a9-57ea-4ece-83fa-2888248b9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preaparting only with Best Features from previous notebook\n",
    "\"\"\"\n",
    "selected_features = [\n",
    "    'Sex',\n",
    "    'Age',\n",
    "    'Height',\n",
    "    'Weight',\n",
    "    'Duration',\n",
    "    'Heart_Rate',\n",
    "    'HR_per_min',\n",
    "    'Age_Group_Adult',\n",
    "    'Age_Group_Senior'\n",
    "]\n",
    "\n",
    "# Extract X and y\n",
    "X = train[selected_features].copy()\n",
    "y = train[\"Calories\"]\n",
    "X_test = test[selected_features].copy()\n",
    "\"\"\"\n",
    "# Data Preaparting\n",
    "train['Sex'] = train['Sex'].map({'male': 1, 'female': 0})\n",
    "test['Sex'] = test['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "X = train.drop(columns=[\"id\", \"Calories\"]) # Drop Target and ID\n",
    "y = train[\"Calories\"] # Define Target\n",
    "\n",
    "X_test = test.drop(columns=[\"id\"]) # Drop ID from Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c573bfc3-4079-4bd2-8ea4-4acac2cb4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac220ea-7c2c-4d86-b48f-42ee7207e864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Running Optuna for RF...\n",
      "✅ RF best params of original features are saved and logged.\n",
      "✅ Running Optuna for HGB...\n",
      "✅ HGB best params of original features are saved and logged.\n",
      "✅ Running Optuna for XGB...\n",
      "✅ XGB best params of original features are saved and logged.\n",
      "✅ Running Optuna for LGBM...\n",
      "✅ LGBM best params of original features are saved and logged.\n",
      "✅ Running Optuna for CAT...\n",
      "✅ CAT best params of original features are saved and logged.\n"
     ]
    }
   ],
   "source": [
    "# Set MLflow location and experiment\n",
    "mlflow.set_tracking_uri(\"file:../logs/mlruns\")\n",
    "mlflow.set_experiment(\"Calories - Optuna Tuning - Original Features\")\n",
    "\n",
    "# Ensure directory for saving best_params\n",
    "Path(\"../logs/best_params_orig_features\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define model configs\n",
    "model_configs = {\n",
    "    \"rf\": {\n",
    "        \"class\": RandomForestRegressor,\n",
    "        \"params\": lambda t: {\n",
    "            \"n_estimators\": t.suggest_int('n_estimators', 50, 300),\n",
    "            \"max_depth\": t.suggest_int('max_depth', 3, 15),\n",
    "            \"max_features\": t.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1\n",
    "        }\n",
    "    },\n",
    "    \"hgb\": {\n",
    "        \"class\": HistGradientBoostingRegressor,\n",
    "        \"params\": lambda t: {\n",
    "            \"learning_rate\": t.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            \"max_depth\": t.suggest_int('max_depth', 3, 10),\n",
    "            \"max_iter\": t.suggest_int('max_iter', 50, 200),\n",
    "            \"l2_regularization\": t.suggest_float('l2_regularization', 0.0, 1.0),\n",
    "            \"random_state\": 42\n",
    "        }\n",
    "    },\n",
    "    \"xgb\": {\n",
    "        \"class\": XGBRegressor,\n",
    "        \"params\": lambda t: {\n",
    "            \"n_estimators\": t.suggest_int('n_estimators', 50, 200),\n",
    "            \"max_depth\": t.suggest_int('max_depth', 3, 10),\n",
    "            \"learning_rate\": t.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            \"subsample\": t.suggest_float('subsample', 0.6, 1.0),\n",
    "            \"colsample_bytree\": t.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            \"gamma\": t.suggest_float('gamma', 0, 5),\n",
    "            \"reg_alpha\": t.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "            \"reg_lambda\": t.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1\n",
    "        }\n",
    "    },\n",
    "    \"lgbm\": {\n",
    "        \"class\": LGBMRegressor,\n",
    "        \"params\": lambda t: {\n",
    "            \"n_estimators\": t.suggest_int('n_estimators', 50, 300),\n",
    "            \"max_depth\": t.suggest_int('max_depth', 3, 15),\n",
    "            \"learning_rate\": t.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            \"num_leaves\": t.suggest_int('num_leaves', 20, 100),\n",
    "            \"subsample\": t.suggest_float('subsample', 0.6, 1.0),\n",
    "            \"colsample_bytree\": t.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            \"reg_alpha\": t.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "            \"reg_lambda\": t.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "            \"random_state\": 42,\n",
    "            \"verbosity\": -1,\n",
    "            \"n_jobs\": -1\n",
    "        }\n",
    "    },\n",
    "    \"cat\": {\n",
    "        \"class\": CatBoostRegressor,\n",
    "        \"params\": lambda t: {\n",
    "            \"iterations\": t.suggest_int(\"iterations\", 100, 500),\n",
    "            \"depth\": t.suggest_int(\"depth\", 4, 10),\n",
    "            \"learning_rate\": t.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"l2_leaf_reg\": t.suggest_float(\"l2_leaf_reg\", 1.0, 10.0),\n",
    "            \"random_seed\": 42,\n",
    "            \"verbose\": 0\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define objective function for Optuna\n",
    "def make_objective(model_class, param_func):\n",
    "    def objective(trial):\n",
    "        model = model_class(**param_func(trial))\n",
    "        score = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=5).mean()\n",
    "        return -score\n",
    "    return objective\n",
    "\n",
    "# Run Optuna tuning, log to MLflow, save best_params\n",
    "studies = {}\n",
    "for name, config in model_configs.items():\n",
    "    print(f\"✅ Running Optuna for {name.upper()}...\")\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"Tuning_{name.upper()}\"):\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(make_objective(config[\"class\"], config[\"params\"]), n_trials=100)\n",
    "\n",
    "        best_params = study.best_params\n",
    "        best_score = study.best_value\n",
    "\n",
    "        # Log to MLflow\n",
    "        mlflow.log_params({f\"{name}__{k}\": v for k, v in best_params.items()})\n",
    "        mlflow.log_metric(f\"{name.upper()}_best_score\", best_score)\n",
    "\n",
    "        # Save best_params to JSON\n",
    "        with open(f\"../logs/best_params_orig_features/{name}.json\", \"w\") as f:\n",
    "            json.dump(best_params, f, indent=2)\n",
    "\n",
    "        print(f\"✅ {name.upper()} best params of original features are saved and logged.\")\n",
    "        studies[name] = study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d36bfae-5866-407c-b382-d967294d0520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/28 10:24:30 INFO mlflow.tracking.fluent: Experiment with name 'Calories - Tuned Models - Original Features' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ RMSLE Scores:\n",
      "RMSLE RF   : 0.06126\n",
      "RMSLE HGB  : 0.06396\n",
      "RMSLE XGB  : 0.06077\n",
      "RMSLE LGBM : 0.06278\n",
      "RMSLE CAT  : 0.06097\n"
     ]
    }
   ],
   "source": [
    "# Set MLflow location and experiment\n",
    "mlflow.set_tracking_uri(\"file:../logs/mlruns\")\n",
    "mlflow.set_experiment(\"Calories - Tuned Models - Original Features\")\n",
    "Path(\"../logs/best_params_orig_features\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Helper Functions\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, np.clip(y_pred, 0, None)))\n",
    "\n",
    "def save_params_to_json(name, params):\n",
    "    with open(f\"../logs/best_params_orig_features/{name}.json\", \"w\") as f:\n",
    "        json.dump(params, f, indent=2)\n",
    "\n",
    "def load_params_from_json(name):\n",
    "    with open(f\"../logs/best_params_orig_features/{name}.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def train_log_model(name, model, params, pred_val, score, mlflow_module):\n",
    "    mlflow.log_params({f\"{name}__{k}\": v for k, v in params.items()})\n",
    "    mlflow.log_metric(f\"RMSLE_{name.upper()}\", score)\n",
    "    signature = infer_signature(X_val, pred_val)\n",
    "    mlflow_module.log_model(model, artifact_path=f\"{name}_model\", signature=signature, input_example=X_val.iloc[:1])\n",
    "    save_params_to_json(name, params)\n",
    "\n",
    "# Load best parameters from JSON\n",
    "model_configs = [\n",
    "    (\"rf\", RandomForestRegressor, load_params_from_json(\"rf\"), mlflow.sklearn),\n",
    "    (\"hgb\", HistGradientBoostingRegressor, load_params_from_json(\"hgb\"), mlflow.sklearn),\n",
    "    (\"xgb\", XGBRegressor, load_params_from_json(\"xgb\"), mlflow.xgboost),\n",
    "    (\"lgbm\", LGBMRegressor, load_params_from_json(\"lgbm\"), mlflow.lightgbm),\n",
    "    (\"cat\", CatBoostRegressor, load_params_from_json(\"cat\"), mlflow.catboost)\n",
    "]\n",
    "\n",
    "# Train and log models\n",
    "with mlflow.start_run(run_name=\"tuned_models_all_5\"):\n",
    "    scores = {}\n",
    "\n",
    "    for name, model_cls, params, mlflow_module in model_configs:\n",
    "        # Extra settings for CatBoost\n",
    "        kwargs = dict(random_state=42) if name != \"cat\" else dict(random_seed=42, verbose=0, train_dir=\"../logs/catboost_logs\")\n",
    "        kwargs.update(params)\n",
    "\n",
    "        model = model_cls(**kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "        val_pred = model.predict(X_val)\n",
    "        score = rmsle(y_val, val_pred)\n",
    "        scores[name.upper()] = score\n",
    "\n",
    "        train_log_model(name, model, params, val_pred, score, mlflow_module)\n",
    "\n",
    "    # === Print RMSLE Scores ===\n",
    "    print(\"\\n✅ RMSLE Scores:\")\n",
    "    for model_name, score in scores.items():\n",
    "        print(f\"RMSLE {model_name:5s}: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "339c0145-fe5f-47b6-863d-fa6434228924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logged: RF Tuned | Score: 0.06126\n",
      "✅ Logged: HGB Tuned | Score: 0.06396\n",
      "✅ Logged: XGB Tuned | Score: 0.06077\n",
      "✅ Logged: LGBM Tuned | Score: 0.06278\n",
      "✅ Logged: CAT Tuned | Score: 0.06097\n",
      "\n",
      "✅ RMSLE Individual Scores:\n",
      "RF   : 0.06126\n",
      "HGB  : 0.06396\n",
      "XGB  : 0.06077\n",
      "LGBM : 0.06278\n",
      "CAT  : 0.06097\n"
     ]
    }
   ],
   "source": [
    "# Define model metadata and MLflow modules\n",
    "model_info = {\n",
    "    \"rf\": (RandomForestRegressor, {\"random_state\": 42}, mlflow.sklearn),\n",
    "    \"hgb\": (HistGradientBoostingRegressor, {\"random_state\": 42}, mlflow.sklearn),\n",
    "    \"xgb\": (XGBRegressor, {\"random_state\": 42}, mlflow.xgboost),\n",
    "    \"lgbm\": (LGBMRegressor, {\"random_state\": 42}, mlflow.lightgbm),\n",
    "    \"cat\": (CatBoostRegressor, {\"random_seed\": 42, \"verbose\": 0, \"train_dir\": \"../logs/catboost_logs\"}, mlflow.catboost)\n",
    "}\n",
    "\n",
    "preds = {}\n",
    "scores = {}\n",
    "\n",
    "# Run all models and log with MLflow\n",
    "with mlflow.start_run(run_name=\"tuned_models_refactored\"):\n",
    "    for name, (cls, const_params, mlflow_module) in model_info.items():\n",
    "        with open(f\"../logs/best_params_orig_features/{name}.json\") as f:\n",
    "            params = json.load(f)\n",
    "        params.update(const_params)\n",
    "        model = cls(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        val_pred = model.predict(X_val)\n",
    "        preds[name] = val_pred\n",
    "\n",
    "        score = rmsle(y_val, val_pred)\n",
    "        scores[name.upper()] = score\n",
    "        log_score(f\"{name.upper()} Tuned\", score, \"Refactored full pipeline - Original Features\")\n",
    "\n",
    "        signature = infer_signature(X_val, val_pred)\n",
    "        mlflow_module.log_model(model, artifact_path=f\"{name}_model\", signature=signature, input_example=X_val.iloc[:1])\n",
    "        mlflow.log_params({f\"{name}__{k}\": v for k, v in params.items()})\n",
    "        mlflow.log_metric(f\"RMSLE_{name.upper()}\", score)\n",
    "\n",
    "    print(\"\\n✅ RMSLE Individual Scores:\")\n",
    "    for model, score in scores.items():\n",
    "        print(f\"{model:5s}: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ba5a3b8-48f6-4dea-8d83-76cb5a0d0cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logged: Ensemble Avg | Score: 0.05995\n",
      "✅ Logged: Ensemble Weighted | Score: 0.05976\n",
      "\n",
      "✅ RMSLE Ensemble Scores:\n",
      "Avg     : 0.05995\n",
      "Weighted: 0.05976\n"
     ]
    }
   ],
   "source": [
    "# Ensemble evaluations\n",
    "val_avg = np.mean(list(preds.values()), axis=0)\n",
    "score_avg = rmsle(y_val, val_avg)\n",
    "log_score(\"Ensemble Avg\", score_avg, \"Simple mean of all 5 models\")\n",
    "mlflow.log_metric(\"RMSLE_ENSEMBLE_AVG\", score_avg)\n",
    "\n",
    "weights = {\"xgb\": 0.3, \"rf\": 0.25, \"cat\": 0.25, \"lgbm\": 0.1, \"hgb\": 0.1}\n",
    "val_weighted = sum(w * preds[k] for k, w in weights.items())\n",
    "score_weighted = rmsle(y_val, val_weighted)\n",
    "log_score(\"Ensemble Weighted\", score_weighted, \"Weighted mean based on model strength\")\n",
    "mlflow.log_metric(\"RMSLE_ENSEMBLE_WEIGHTED\", score_weighted)\n",
    "\n",
    "print(\"\\n✅ RMSLE Ensemble Scores:\")\n",
    "print(f\"Avg     : {score_avg:.5f}\")\n",
    "print(f\"Weighted: {score_weighted:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f948ef56-0f64-488b-a9d5-874d3b902a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logged: Ensemble Stacking | Score: 0.05996\n",
      "\n",
      "✅ RMSLE Stacking Ensemble:\n",
      "Stacking : 0.05996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# === 1. Create validation meta-features for stacking\n",
    "train_meta = np.column_stack([preds[model] for model in [\"rf\", \"hgb\", \"xgb\", \"lgbm\", \"cat\"]])\n",
    "meta_model = Ridge(alpha=1.0, random_state=42)\n",
    "meta_model.fit(train_meta, y_val)\n",
    "\n",
    "# === 2. Generate test predictions for each base model\n",
    "test_preds = {}\n",
    "for name, (cls, const_params, _) in model_info.items():\n",
    "    with open(f\"../logs/best_params/{name}.json\") as f:\n",
    "        params = json.load(f)\n",
    "    params.update(const_params)\n",
    "    model = cls(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_preds[name] = model.predict(X_test)\n",
    "\n",
    "# === 3. Stack test predictions for meta model input\n",
    "test_meta = np.column_stack([test_preds[k] for k in [\"rf\", \"hgb\", \"xgb\", \"lgbm\", \"cat\"]])\n",
    "final_pred = meta_model.predict(test_meta)\n",
    "\n",
    "# === 4. Optional: Evaluate on validation set to log stacking performance\n",
    "val_stack_pred = meta_model.predict(train_meta)\n",
    "score_stack = rmsle(y_val, val_stack_pred)\n",
    "\n",
    "log_score(\"Ensemble Stacking\", score_stack, \"Ridge meta-model on base model outputs\")\n",
    "mlflow.log_metric(\"RMSLE_ENSEMBLE_STACKING\", score_stack)\n",
    "\n",
    "print(\"\\n✅ RMSLE Stacking Ensemble:\")\n",
    "print(f\"Stacking : {score_stack:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "936ef4ee-2ef9-4cf8-8f39-4452988ad948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission saved: ../outputs/submission_stacked_ensemble.csv\n",
      "✅ Submission saved: ../outputs/submission_avg_ensemble.csv\n",
      "✅ Submission saved: ../outputs/submission_weighted_ensemble.csv\n"
     ]
    }
   ],
   "source": [
    "# === 1. Stacked Ensemble (Ridge)\n",
    "sample[\"Calories\"] = final_pred\n",
    "submission_path_stack = \"../outputs/submission_stacked_ensemble.csv\"\n",
    "sample.to_csv(submission_path_stack, index=False)\n",
    "print(f\"✅ Submission saved: {submission_path_stack}\")\n",
    "\n",
    "# === 2. Simple Average Ensemble\n",
    "val_avg = np.mean(list(preds.values()), axis=0)\n",
    "avg_test = np.mean([test_preds[k] for k in [\"rf\", \"hgb\", \"xgb\", \"lgbm\", \"cat\"]], axis=0)\n",
    "\n",
    "sample[\"Calories\"] = avg_test\n",
    "submission_path_avg = \"../outputs/submission_avg_ensemble.csv\"\n",
    "sample.to_csv(submission_path_avg, index=False)\n",
    "print(f\"✅ Submission saved: {submission_path_avg}\")\n",
    "\n",
    "# === 3. Weighted Average Ensemble\n",
    "weights = {\"xgb\": 0.3, \"rf\": 0.25, \"cat\": 0.25, \"lgbm\": 0.1, \"hgb\": 0.1}\n",
    "weighted_test = sum(weights[k] * test_preds[k] for k in weights)\n",
    "\n",
    "sample[\"Calories\"] = weighted_test\n",
    "submission_path_weighted = \"../outputs/submission_weighted_ensemble.csv\"\n",
    "sample.to_csv(submission_path_weighted, index=False)\n",
    "print(f\"✅ Submission saved: {submission_path_weighted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f52213a7-25df-4cff-b7d8-97488ae0c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare variables for Optuna weighted ensemble\n",
    "val_xgb = preds[\"xgb\"]\n",
    "val_cat = preds[\"cat\"]\n",
    "val_rf = preds[\"rf\"]\n",
    "val_lgbm = preds[\"lgbm\"]\n",
    "val_hgb = preds[\"hgb\"]\n",
    "\n",
    "test_xgb = test_preds[\"xgb\"]\n",
    "test_cat = test_preds[\"cat\"]\n",
    "test_rf = test_preds[\"rf\"]\n",
    "test_lgbm = test_preds[\"lgbm\"]\n",
    "test_hgb = test_preds[\"hgb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c2ef20a-3ab7-4c56-a13f-60ce83c8e265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Best normalized weights found: {'w_xgb': 0.1477070571366856, 'w_cat': 0.35199589837970613, 'w_rf': 0.3608387220319866, 'w_lgbm': 0.06810229309383056, 'w_hgb': 0.07135602935779119}\n",
      "📉 Best RMSLE: 0.0596955085912612\n",
      "✅ Submission saved as '../outputs/submission_tuned_weighted_ensemble.csv'\n"
     ]
    }
   ],
   "source": [
    "# === Define Optuna objective ===\n",
    "def weight_objective(trial):\n",
    "    # Suggest weights for each model between 0 and 1\n",
    "    w_xgb = trial.suggest_float(\"w_xgb\", 0, 1)\n",
    "    w_cat = trial.suggest_float(\"w_cat\", 0, 1)\n",
    "    w_rf = trial.suggest_float(\"w_rf\", 0, 1)\n",
    "    w_lgbm = trial.suggest_float(\"w_lgbm\", 0, 1)\n",
    "    w_hgb = trial.suggest_float(\"w_hgb\", 0, 1)\n",
    "\n",
    "    # Normalize weights to sum to 1\n",
    "    total = w_xgb + w_cat + w_rf + w_lgbm + w_hgb\n",
    "    w_xgb /= total\n",
    "    w_cat /= total\n",
    "    w_rf /= total\n",
    "    w_lgbm /= total\n",
    "    w_hgb /= total\n",
    "\n",
    "    # Create blended prediction\n",
    "    val_pred = (\n",
    "        w_xgb * val_xgb +\n",
    "        w_cat * val_cat +\n",
    "        w_rf * val_rf +\n",
    "        w_lgbm * val_lgbm +\n",
    "        w_hgb * val_hgb\n",
    "    )\n",
    "\n",
    "    # Calculate RMSLE\n",
    "    return rmsle(y_val, val_pred)\n",
    "\n",
    "# === Run Optuna ===\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(weight_objective, n_trials=300)\n",
    "\n",
    "# === Get best weights ===\n",
    "best_weights = study.best_params\n",
    "total = sum(best_weights.values())\n",
    "normalized_weights = {k: v / total for k, v in best_weights.items()}\n",
    "print(\"\\n🎯 Best normalized weights found:\", normalized_weights)\n",
    "print(\"📉 Best RMSLE:\", study.best_value)\n",
    "\n",
    "# === Apply weights to test set ===\n",
    "test_weighted = (\n",
    "    normalized_weights['w_xgb'] * test_xgb +\n",
    "    normalized_weights['w_cat'] * test_cat +\n",
    "    normalized_weights['w_rf'] * test_rf +\n",
    "    normalized_weights['w_lgbm'] * test_lgbm +\n",
    "    normalized_weights['w_hgb'] * test_hgb\n",
    ")\n",
    "\n",
    "# === Save submission ===\n",
    "sample['Calories'] = test_weighted\n",
    "sample.to_csv('../outputs/submission_tuned_weighted_ensemble.csv', index=False)\n",
    "print(\"✅ Submission saved as '../outputs/submission_tuned_weighted_ensemble.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "935439f8-ffb0-46aa-aa99-ae50eb8526c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "def send_sms(phone_email, subject, body):\n",
    "    msg = MIMEText(body)\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = \"your_email@gmail.com\"\n",
    "    msg['To'] = phone_email\n",
    "\n",
    "    with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n",
    "        server.login(\"saayedalam@gmail.com\", \"tbac orha quvt mzgs\")  # ← Paste app password here\n",
    "        server.send_message(msg)\n",
    "\n",
    "# Send to Fido via email-to-SMS\n",
    "send_sms(\"saayedalam@gmail.com\", \"ML Job\", \"✅ Model tuning is complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a1e80-c61a-4c2a-b079-e5c228cf0d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data-lab)",
   "language": "python",
   "name": "data-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
